{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Kodo-python Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the getting started ipython notebook for kodo-python.\n",
    "\n",
    "This guide is intended for newcomers to the kodo library. The guide will in tiny steps guide you through the creation and usage of both encoders and decoders.\n",
    "Even though this guide focuses on the the python language bindings of kodo - similar APIs exists for other languages including C, C++ and Java."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Importing kodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with Kodo-python, you obviously need to have it installed and available. To ensure that's the case, try importing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kodo imported Succesfully\n"
     ]
    }
   ],
   "source": [
    "# try importing the kodo module\n",
    "try:\n",
    "    import kodo\n",
    "    print(\"Kodo imported Succesfully\")\n",
    "except ImportError:\n",
    "    print(\"Unable to import kodo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the import worked, you are ready to move on to the next step. Otherwise please (re)visit the README.rst for installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In kodo, both encoders and decoders are created using factories. Doing so allows efficient memory management and reuse of various components and computations. \n",
    "\n",
    "Therefore, before creating an encoder, let's look at the encoder factories provided by the ``kodo`` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullVectorEncoderFactoryBinary\n",
      "FullVectorEncoderFactoryBinary16\n",
      "FullVectorEncoderFactoryBinary4\n",
      "FullVectorEncoderFactoryBinary8\n",
      "NoCodeEncoderFactory\n",
      "OnTheFlyEncoderFactoryBinary\n",
      "OnTheFlyEncoderFactoryBinary16\n",
      "OnTheFlyEncoderFactoryBinary4\n",
      "OnTheFlyEncoderFactoryBinary8\n",
      "PerpetualEncoderFactoryBinary\n",
      "PerpetualEncoderFactoryBinary16\n",
      "PerpetualEncoderFactoryBinary4\n",
      "PerpetualEncoderFactoryBinary8\n",
      "SlidingWindowEncoderFactoryBinary\n",
      "SlidingWindowEncoderFactoryBinary16\n",
      "SlidingWindowEncoderFactoryBinary4\n",
      "SlidingWindowEncoderFactoryBinary8\n",
      "SparseFullVectorEncoderFactoryBinary\n",
      "SparseFullVectorEncoderFactoryBinary16\n",
      "SparseFullVectorEncoderFactoryBinary4\n",
      "SparseFullVectorEncoderFactoryBinary8\n"
     ]
    }
   ],
   "source": [
    "# print all members containing \"Factory\" and \"Encoder\"\n",
    "print(\"\\n\".join([item for item in dir(kodo) if all([keyword in item for keyword in [\"Factory\", \"Encoder\"]])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the output, many different encoder factories exists. Most of these have decoder factory counterparts.\n",
    "The attentive reader will maybe have seen a pattern from the factory names. The factory names are, with some exceptions, a combination of the encoding algorithm and the underlying finite field.\n",
    "\n",
    "For this walkthrough we pick the full vector factory using the binary field, i.e. the *``FullVector``*``EncoderFactory``*``Binary``* factory.\n",
    "\n",
    "Note: *For this guide, the choice of encoding factory, should be interchangable. For this reason I'll define the factory class as ``EncoderFactory``.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the full vector binary encoder factory as EncoderFactory\n",
    "EncoderFactory = kodo.FullVectorEncoderFactoryBinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using python's ``help`` function, it's easy to inspect which arguments are needed for the  ``EncoderFactory``'s constructor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method __init__:\n",
      "\n",
      "__init__(...) unbound kodo.FullVectorEncoderFactoryBinary method\n",
      "    Factory constructor.\n",
      "    \n",
      "            :param max_symbols: The maximum symbols the coders can expect.\n",
      "            :param max_symbol_size: The maximum size of a symbol in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get information about the encoder factory's __init__ function\n",
    "help(EncoderFactory.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to create a factory, we need to pick the ``max_symbols`` and ``max_symbol_size``.\n",
    "These parameters determines upper bounds to the encoders created by the factory.\n",
    "\n",
    "The proper values to pick depends on the use case, we'll pick the numbers 4 and 32 for the max_symbols and max_symbol_size, respectively.\n",
    "These numbers are very low, but they should serve us well for this educational example.\n",
    "\n",
    "Let's create an encoder_factory object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_symbols = 4\n",
    "max_symbol_size = 32\n",
    "\n",
    "encoder_factory = EncoderFactory(\n",
    "    max_symbols=max_symbols,\n",
    "    max_symbol_size=max_symbol_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the object's ``build`` method to create encoders, but other methods are also available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\n",
      "max_block_size\n",
      "max_payload_size\n",
      "max_symbol_size\n",
      "max_symbols\n",
      "set_symbol_size\n",
      "set_symbols\n",
      "symbol_size\n",
      "symbols\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(encoder_factory) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be used to either get information about the created factory or set values used for the encoders to be created using the ``build`` method.\n",
    "\n",
    "Let's print out the maximum block size, i.e. the maximum amount of data that can be encoded during each generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max block size: 128\n"
     ]
    }
   ],
   "source": [
    "max_block_size = encoder_factory.max_block_size()\n",
    "print(\"Max block size: {}\".format(max_block_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the maximum block size is directly correlated with the previously set ``max_symbols`` and ``max_symbol_size``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated max block size: 128\n"
     ]
    }
   ],
   "source": [
    "calculated_max_block_size = max_symbols * max_symbol_size\n",
    "print(\"Calculated max block size: {}\".format(calculated_max_block_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough talk - let's create an encoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = encoder_factory.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic, we've build our first encoder! Let's see what we can use it for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size\n",
      "in_systematic_phase\n",
      "is_systematic_on\n",
      "payload_size\n",
      "rank\n",
      "set_symbol\n",
      "set_symbols\n",
      "set_systematic_off\n",
      "set_systematic_on\n",
      "symbol_size\n",
      "symbols\n",
      "trace\n",
      "write_payload\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(encoder) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the state of our newly created encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_systematic_on: True\n",
      "in_systematic_phase: False\n",
      "payload_size: 38\n",
      "rank: 0\n",
      "symbol_size: 32\n",
      "symbols: 4\n"
     ]
    }
   ],
   "source": [
    "def print_encoder_state(encoder):\n",
    "    print(\n",
    "        \"block_size: {}\\n\"\n",
    "        \"is_systematic_on: {}\\n\"\n",
    "        \"in_systematic_phase: {}\\n\"\n",
    "        \"payload_size: {}\\n\"\n",
    "        \"rank: {}\\n\"\n",
    "        \"symbol_size: {}\\n\"\n",
    "        \"symbols: {}\".format(\n",
    "            encoder.block_size(),\n",
    "            encoder.is_systematic_on(),\n",
    "            encoder.in_systematic_phase(),\n",
    "            encoder.payload_size(),\n",
    "            encoder.rank(),\n",
    "            encoder.symbol_size(),\n",
    "            encoder.symbols())\n",
    "    )\n",
    "print_encoder_state(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ``write_payload`` method to encode the data, but since we have yet to tell encoder what data to encode, we can't use it yet.\n",
    "This can be seen from the encoder rank which is 0.\n",
    "\n",
    "Let's create some data to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data string: 128\n"
     ]
    }
   ],
   "source": [
    "data_in = (\n",
    "    \"The size of this data is exactly 128 bytes \"\n",
    "    \"which means it will fit perfectly in a single generation. \"\n",
    "    \"That is very lucky, indeed!\"\n",
    ")\n",
    "print(\"Length of data string: {}\".format(len(data_in)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodo uses python strings as data objects, which means each character represents a byte. Let's set the data to encode on the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder.set_symbols(data_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now be able to see how the state of the encoder has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_systematic_on: True\n",
      "in_systematic_phase: True\n",
      "payload_size: 38\n",
      "rank: 4\n",
      "symbol_size: 32\n",
      "symbols: 4\n"
     ]
    }
   ],
   "source": [
    "print_encoder_state(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the rank is now equal to the number of symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.rank() == max_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only encode if the rank is > 0.\n",
    "\n",
    "Let's encode some packets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packet1: �\u0000\u0000\u0000\u0000The size of this data is exactly\n",
      "packet2: �\u0000\u0000\u0000\u0001 128 bytes which means it will f\n",
      "packet3: �\u0000\u0000\u0000\u0002it perfectly in a single generat\n",
      "packet4: �\u0000\u0000\u0000\u0003ion. That is very lucky, indeed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "packet1 = encoder.write_payload()\n",
    "packet2 = encoder.write_payload()\n",
    "packet3 = encoder.write_payload()\n",
    "packet4 = encoder.write_payload()\n",
    "\n",
    "print(\n",
    "    \"packet1: {}\\n\"\n",
    "    \"packet2: {}\\n\"\n",
    "    \"packet3: {}\\n\"\n",
    "    \"packet4: {}\\n\".format(\n",
    "        packet1,\n",
    "        packet2,\n",
    "        packet3,\n",
    "        packet4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all the packets are prefixed with ``�`` - this is python trying to print the packet header containing the symbol id, as a character.\n",
    "The reason why the content of the packets are readable is that the encoder is in systematic phase. Systematic means that the encoder starts by leaving each symbol uncoded in the first iteration.\n",
    "Because we've set the generation size to be 4 symbols, and we've created 4 packets - the encoder is no longer in systematic phase:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.in_systematic_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that any subsequent we generate will be encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packet5: \u0000+\u001d",
      "696s_kp1</$<woiy)h`l806t,alj}(>\n"
     ]
    }
   ],
   "source": [
    "packet5 = encoder.write_payload()\n",
    "print(\"packet5: {}\".format(packet5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, depending on how the data have been encoded, the data will now most likely be unreadable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a decoder factory and a decoder so that we can decode our newly generated packets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_factory = kodo.FullVectorDecoderFactoryBinary(max_symbols, max_symbol_size)\n",
    "decoder = decoder_factory.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the methods that are available for the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size\n",
      "copy_symbols\n",
      "is_complete\n",
      "payload_size\n",
      "rank\n",
      "read_payload\n",
      "symbol_size\n",
      "symbols\n",
      "symbols_uncoded\n",
      "trace\n",
      "write_payload\n"
     ]
    }
   ],
   "source": [
    "# Print all public members\n",
    "print(\"\\n\".join([item for item in dir(decoder) if not item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the output, the encoder and decoder shares a few methods. Most of these have the same meaning.\n",
    "Let's inspect the state of our newly created decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 128\n",
      "is_complete: False\n",
      "payload_size: 38\n",
      "rank: 0\n",
      "symbol_size: 32\n",
      "symbols: 4\n",
      "symbols_uncoded: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_decoder_state(decoder):\n",
    "    print(\n",
    "        \"block_size: {}\\n\"\n",
    "        \"is_complete: {}\\n\"\n",
    "        \"payload_size: {}\\n\"\n",
    "        \"rank: {}\\n\"\n",
    "        \"symbol_size: {}\\n\"\n",
    "        \"symbols: {}\\n\"\n",
    "        \"symbols_uncoded: {}\\n\".format(\n",
    "            decoder.block_size(),\n",
    "            decoder.is_complete(),\n",
    "            decoder.payload_size(),\n",
    "            decoder.rank(),\n",
    "            decoder.symbol_size(),\n",
    "            decoder.symbols(),\n",
    "            decoder.symbols_uncoded())\n",
    "    )\n",
    "print_decoder_state(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's probably the most interesting here is the rank. The rank is describes the number of innovative packets recieved.\n",
    "Hence if we read one of our previously generated packets, we should see the rank increase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.read_payload(packet1)\n",
    "decoder.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it does. Also, since the read packet was uncoded we will see that the number of uncoded symbols\n",
    "in the decoder has increased from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.symbols_uncoded()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can now try to read the 5th packet, and see what it does to the state. The unique thing about the 5th packet, is that it's the only one which have been encoded, due to our encoder being systematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 1\n",
      "symbols_uncoded: 1\n"
     ]
    }
   ],
   "source": [
    "decoder.read_payload(packet5)\n",
    "print(\n",
    "    \"rank: {}\\n\"\n",
    "    \"symbols_uncoded: {}\".format(\n",
    "        decoder.rank(),\n",
    "        decoder.symbols_uncoded()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank is 2, which means that we've read two (innovative) packets.\n",
    "The number of uncoded symbols is 1 since the first symbol we read was uncoded.\n",
    "\n",
    "In case the 5th packet were a combination of the first packet and any other packet, we would actually have 2 uncoded symbols. \n",
    "But due to performance implications the ``symbols_uncoded`` method will still return 1 - atleast for the full vector algorithm. This can be seen from the documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method symbols_uncoded:\n",
      "\n",
      "symbols_uncoded(...) method of kodo.FullVectorDecoderBinary instance\n",
      "    Returns the number of uncoded symbols currently known.\n",
      "    \n",
      "    Depending on the algorithm used the true number of uncoded\n",
      "    symbols may be higher.\n",
      "    The reason for this uncertainty is the some algorithms, for\n",
      "    performance reasons, choose to not keep track of the exact\n",
      "    status of the decoding matrix.\n",
      "    It is however guaranteed that at least this amount of uncoded\n",
      "    symbols exist.\n",
      "            :returns: The number of symbols which have been uncoded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(decoder.symbols_uncoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If extract the current data in the decoder we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The size of this data is exactly________________________________________________________________________________________________'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.copy_symbols().replace('\\x00', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first part of the string is readable. Depending on the encoding of the 5th other parts of the string may or may not be readable.\n",
    "If we feed the same packet(s) to the decoder multiple times we will not increase it's rank - no matter how many times we do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "decoder.read_payload(packet1)\n",
    "print(decoder.rank())\n",
    "decoder.read_payload(packet5)\n",
    "print(decoder.rank())\n",
    "decoder.read_payload(packet1)\n",
    "print(decoder.rank())\n",
    "decoder.read_payload(packet5)\n",
    "print(decoder.rank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the data we feed the decoder isn't innovative.\n",
    "If we start feeding the decoder new data, we will at one point have a complete decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "while not decoder.is_complete():\n",
    "    decoder.read_payload(encoder.write_payload())\n",
    "    print(decoder.rank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when the decoder is complete we can extract the whole string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The size of this data is exactly 128 bytes which means it will fit perfectly in a single generation. That is very lucky, indeed!'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.copy_symbols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with this, I will end the getting started guide. I hope you learned something and are eager to dive into the would of error correcting codes - in particular network coding.\n",
    "\n",
    "For more information and inspiration please look through some of the many examples available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
